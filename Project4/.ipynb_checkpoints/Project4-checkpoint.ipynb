{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26957997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def estep(X,mu,pi,cov):\n",
    "    \"\"\"E-step: Softly assigns each datapoint to a gaussian component\n",
    "\n",
    "    Args:\n",
    "        X: (n, d) array holding the data\n",
    "        mixture: the current gaussian mixture\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: (n, K) array holding the soft counts\n",
    "            for all components for all examples\n",
    "        float: log-likelihood of the assignment\n",
    "    \"\"\"\n",
    "    from scipy.stats import multivariate_normal\n",
    "    n, d = X.shape\n",
    "    K,_ = mu.shape  # Number of components in the mixture\n",
    "    # Covariances of the components\n",
    "\n",
    "    # Initialize the responsibility matrix (soft counts)\n",
    "    responsibilities = np.zeros((n, K))\n",
    "\n",
    "    # Calculate the responsibilities for each data point and each component\n",
    "    for k in range(K):\n",
    "        # Use multivariate_normal.pdf to compute the probability density function\n",
    "        responsibilities[:, k] = pi[k] * multivariate_normal.pdf(X, mean=mu[k], cov=cov[k])\n",
    "    \n",
    "    # Normalize the responsibilities to get soft counts\n",
    "    responsibilities_sum = responsibilities.sum(axis=1, keepdims=True)\n",
    "    responsibilities /= responsibilities_sum\n",
    "\n",
    "    # Calculate the log-likelihood of the assignment\n",
    "    log_likelihood = np.sum(np.log(np.sum(responsibilities_sum * pi, axis=1)))\n",
    "    \n",
    "    return responsibilities, log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d0f3b45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-24.512532330086675\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[-1], [0], [4], [5], [6]])\n",
    "# theta0 = np.array([0.5, 0.5, 6, 7, 1, 4])\n",
    "\n",
    "mu = np.array([[6],[7]])\n",
    "pi = np.array([0.5,0.5])\n",
    "var = np.array([1,4])\n",
    "\n",
    "responsibilities, log_likelihood = estep(X,mu,pi,var)\n",
    "print(log_likelihood)\n",
    "print(type(responsibilities))\n",
    "\n",
    "# new_mixture = mstep(X, responsibilities)\n",
    "# print(new_mixture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77945c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= np.array([[0.85794562, 0.84725174],\n",
    " [0.6235637,  0.38438171],\n",
    " [0.29753461, 0.05671298],\n",
    " [0.27265629, 0.47766512],\n",
    " [0.81216873, 0.47997717],\n",
    " [0.3927848,  0.83607876],\n",
    " [0.33739616, 0.64817187],\n",
    " [0.36824154, 0.95715516],\n",
    " [0.14035078, 0.87008726],\n",
    " [0.47360805, 0.80091075],\n",
    " [0.52047748, 0.67887953],\n",
    " [0.72063265, 0.58201979],\n",
    " [0.53737323, 0.75861562],\n",
    " [0.10590761, 0.47360042],\n",
    " [0.18633234, 0.73691818]])\n",
    "post=np.array([[0.15765074, 0.20544344, 0.17314824, 0.15652173, 0.12169798, 0.18553787],\n",
    " [0.1094766,  0.22310587, 0.24109142, 0.0959303,  0.19807563, 0.13232018],\n",
    " [0.22679645, 0.36955206, 0.02836173, 0.03478709, 0.00807236, 0.33243031],\n",
    " [0.16670188, 0.18637975, 0.20964608, 0.17120102, 0.09886116, 0.16721011],\n",
    " [0.04250305, 0.22996176, 0.05151538, 0.33947585, 0.18753121, 0.14901275],\n",
    " [0.09799086, 0.28677458, 0.16895715, 0.21054678, 0.0069597 , 0.22877093],\n",
    " [0.16764519, 0.16897033, 0.25848053, 0.18674186, 0.09846462, 0.11969746],\n",
    " [0.28655211, 0.02473762, 0.27387452, 0.27546459, 0.08641467, 0.05295649],\n",
    " [0.11353057, 0.13090863, 0.20522811, 0.15786368, 0.35574052, 0.03672849],\n",
    " [0.10510461, 0.08116927, 0.3286373 , 0.12745369, 0.23464272, 0.12299241],\n",
    " [0.09757735, 0.06774952, 0.40286261, 0.08481828, 0.1206645 , 0.22632773],\n",
    " [0.24899344, 0.02944918, 0.25413459, 0.02914503, 0.29614373, 0.14213403],\n",
    " [0.35350682, 0.21890411, 0.26755234, 0.01418274, 0.10235276, 0.04350123],\n",
    " [0.15555757, 0.06236572, 0.16703133, 0.21760554, 0.03369562, 0.36374421],\n",
    " [0.1917808, 0.08982788, 0.17710673, 0.03179658, 0.19494387, 0.31454414]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6be47cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'means': array([[0.43216722, 0.64675402],\n",
       "        [0.46139681, 0.57129172],\n",
       "        [0.44658753, 0.68978041],\n",
       "        [0.44913747, 0.66937822],\n",
       "        [0.47080526, 0.68008664],\n",
       "        [0.40532311, 0.57364425]]),\n",
       " 'covariances': array([0.05218451, 0.06230449, 0.03538519, 0.05174859, 0.04524244,\n",
       "        0.05831186]),\n",
       " 'weights': array([0.1680912 , 0.15835331, 0.21384187, 0.14223565, 0.14295074,\n",
       "        0.17452722])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mstep(X: np.ndarray, post: np.ndarray):\n",
    "    \"\"\"M-step: Updates the gaussian mixture by maximizing the log-likelihood\n",
    "    of the weighted dataset\n",
    "\n",
    "    Args:\n",
    "        X: (n, d) array holding the data\n",
    "        post: (n, K) array holding the soft counts\n",
    "            for all components for all examples\n",
    "\n",
    "    Returns:\n",
    "        GaussianMixture: the new gaussian mixture\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    K = post.shape[1]\n",
    "\n",
    "    # Update weights\n",
    "    weights = post.sum(axis=0) / n\n",
    "    \n",
    "    # Update means\n",
    "    means = np.dot(post.T, X) / post.sum(axis=0)[:, np.newaxis]\n",
    "\n",
    "    # Update covariances\n",
    "    covariances = np.zeros((K,))\n",
    "    \n",
    "    for k in range(K):\n",
    "        dist_X=0\n",
    "        for i in range(n):\n",
    "            dist_X += (post.T[k,i] * np.linalg.norm(X[i] - means[k,:])**2)\n",
    "        covariances [k] = np.array(dist_X).sum()\n",
    "    covariances = covariances / (post.sum(axis=0) * d)\n",
    "    # Create a new GaussianMixture instance with the updated parameters\n",
    "    new_mixture = {\"means\":means, \"covariances\":covariances, \"weights\":weights}\n",
    "\n",
    "    return new_mixture\n",
    "mstep(X,post)\n",
    "# [0.05218451 0.06230449 0.03538519 0.05174859 0.04524244 0.05831186]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "77dc9405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6350259585621174e-05 7.604494140281164e-06 7.944345045836194e-05 2.691617567136991e-05\n",
      "0.12546780795591733 0.05835498851857814 0.6096291947701517 0.20654800875535287\n"
     ]
    }
   ],
   "source": [
    "a = 0.25*(1/((2*math.pi*5.93)**2.5))*math.exp(-(1/(2*5.93))*7)\n",
    "b = 0.25*(1/((2*math.pi*4.87)**2.5))*math.exp(-(1/(2*4.87))*18)\n",
    "c = 0.25*(1/((2*math.pi*3.99)**2.5))*math.exp(-(1/(2*3.99))*0)\n",
    "d = 0.25*(1/((2*math.pi*4.51)**2.5))*math.exp(-(1/(2*4.51))*7)\n",
    "print(a,b,c,d)\n",
    "s = a + b + c+ d\n",
    "print(a/s,b/s,c/s,d/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3b83195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "X=np.array(\n",
    "[[2., 5., 3., 0., 0.],\n",
    " [3., 5., 0., 4., 3.],\n",
    " [2., 0., 3., 3., 1.],\n",
    " [4., 0., 4., 5., 2.],\n",
    " [3., 4., 0., 0., 4.],\n",
    " [1., 0., 4., 5., 5.],\n",
    " [2., 5., 0., 0., 1.],\n",
    " [3., 0., 5., 4., 3.],\n",
    " [0., 5., 3., 3., 3.],\n",
    " [2., 0., 0., 3., 3.],\n",
    " [3., 4., 3., 3., 3.],\n",
    " [1., 5., 3., 0., 1.],\n",
    " [4., 5., 3., 4., 3.],\n",
    " [1., 4., 0., 5., 2.],\n",
    " [1., 5., 3., 3., 5.],\n",
    " [3., 5., 3., 4., 3.],\n",
    " [3., 0., 0., 4., 2.],\n",
    " [3., 5., 3., 5., 1.],\n",
    " [2., 4., 5., 5., 0.],\n",
    " [2., 5., 4., 4., 2.]])\n",
    "K=4\n",
    "Mu=np.array([[2., 4., 5., 5., 0.],\n",
    " [3., 5., 0., 4., 3.],\n",
    " [2., 5., 4., 4., 2.],\n",
    " [0., 5., 3., 3., 3.]])\n",
    "Var= np.array([5.93, 4.87, 3.99, 4.51])\n",
    "P= np.array([0.25, 0.25, 0.25, 0.25])\n",
    "\n",
    "def posterior_prob(X,var,Mu,p):\n",
    "    temp = X[X != 0] - Mu[np.where(X != 0)[0]]\n",
    "#     temp = X - Mu\n",
    "    # doing dot product\n",
    "    # for finding\n",
    "    # sum of the squares\n",
    "    sum_sq = np.dot(temp.T, temp)\n",
    "    # Doing squareroot and\n",
    "    # printing Euclidean distance\n",
    "    dist = np.sqrt(sum_sq)**2\n",
    "    return p*(1/((2*math.pi*var)**(5/2)))*math.exp(-(1/(2*var))*dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1fc3b8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1341517 , 0.11984366, 0.48581388, 0.26019077]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,d=X.shape\n",
    "post = np.zeros((1,K))\n",
    "i=0\n",
    "for j in range(K):\n",
    "    post[:,j] = posterior_prob(X[i],Var[j],Mu[j],P[j])\n",
    "post /=post.sum()\n",
    "post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ac0fc2d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1341517 , 0.11984366, 0.48581388, 0.26019077],\n",
       "       [0.07654379, 0.34446521, 0.44125516, 0.13773584],\n",
       "       [0.13436575, 0.10065547, 0.53062813, 0.23435066],\n",
       "       [0.20243395, 0.10057201, 0.62221332, 0.07478073],\n",
       "       [0.0696132 , 0.38890324, 0.37057151, 0.17091206],\n",
       "       [0.06575143, 0.08048187, 0.43466588, 0.41910082],\n",
       "       [0.16841571, 0.19520457, 0.4735884 , 0.16279132],\n",
       "       [0.14177026, 0.04502806, 0.66271021, 0.15049147],\n",
       "       [0.04727836, 0.12639235, 0.39877683, 0.42755245],\n",
       "       [0.06637157, 0.26464179, 0.41627503, 0.25271161],\n",
       "       [0.07715067, 0.18612696, 0.50647898, 0.23024339],\n",
       "       [0.14478994, 0.07462302, 0.48306238, 0.29752466],\n",
       "       [0.08544132, 0.24851049, 0.53837544, 0.12767275],\n",
       "       [0.15564425, 0.18919874, 0.43869338, 0.21646363],\n",
       "       [0.02553529, 0.1258932 , 0.29235844, 0.55621307],\n",
       "       [0.07604748, 0.19032469, 0.54189543, 0.1917324 ],\n",
       "       [0.11962011, 0.29291411, 0.47129881, 0.11616697],\n",
       "       [0.19275595, 0.13517877, 0.56734832, 0.10471696],\n",
       "       [0.29321816, 0.02707198, 0.54215911, 0.13755074],\n",
       "       [0.12546781, 0.05835499, 0.60962919, 0.20654801]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,d=X.shape\n",
    "post = np.zeros((n,K))\n",
    "for j in range(K):\n",
    "    for i in range(n):\n",
    "        post[i,j] = posterior_prob(X[i],Var[j],Mu[j],P[j])\n",
    "post_sum = post.sum(axis=1, keepdims=True)\n",
    "post /=post_sum\n",
    "post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e61c4bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ffd38e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "def estep(X,var,Mu,p):\n",
    "    n, d = X.shape\n",
    "    K, _ = Mu.shape\n",
    "\n",
    "    log_soft_assignments = np.zeros((n, K))\n",
    "    \n",
    "    from scipy.stats import multivariate_normal\n",
    "    for j in range(K):\n",
    "        for i in range(n):\n",
    "            if np.count_nonzero(X[i]) != 0:\n",
    "                #             X[i][X[i] == 0] = Mu[j][X[i] == 0]\n",
    "                temp = X[i][X[i] != 0] - Mu[j][np.where(X[i] != 0)[0]]\n",
    "#             temp = X[i]-Mu[j]\n",
    "                sum_sq = np.dot(temp.T, temp)\n",
    "                dist = np.sqrt(sum_sq)**2\n",
    "                # Calculate the log probability of each data point under component j\n",
    "                log_prob = np.log((1/((2*math.pi*var[j])**(d/2)))*math.exp(-(1/(2*var[j]))*dist))\n",
    "            else:\n",
    "                log_prob = np.log(1)    \n",
    "\n",
    "            # Add the log weight of component j\n",
    "            log_soft_assignments[i, j] = log_prob + np.log(p[j] + 1e-16)\n",
    "\n",
    "    # Calculate the log-likelihood of the assignment\n",
    "    log_likelihood = np.sum(logsumexp(log_soft_assignments, axis=1))\n",
    "\n",
    "    # Convert log probabilities to probabilities\n",
    "    soft_assignments = np.exp(log_soft_assignments - logsumexp(log_soft_assignments, axis=1)[:, np.newaxis])\n",
    "\n",
    "    return soft_assignments, log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b414ffec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 5., 3.])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][X[0] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "66911b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][X[0] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9acb7e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.1341517 , 0.11984366, 0.48581388, 0.26019077],\n",
       "        [0.07654379, 0.34446521, 0.44125516, 0.13773584],\n",
       "        [0.13436575, 0.10065547, 0.53062813, 0.23435066],\n",
       "        [0.20243395, 0.10057201, 0.62221332, 0.07478073],\n",
       "        [0.0696132 , 0.38890324, 0.37057151, 0.17091206],\n",
       "        [0.06575143, 0.08048187, 0.43466588, 0.41910082],\n",
       "        [0.16841571, 0.19520457, 0.4735884 , 0.16279132],\n",
       "        [0.14177026, 0.04502806, 0.66271021, 0.15049147],\n",
       "        [0.04727836, 0.12639235, 0.39877683, 0.42755245],\n",
       "        [0.06637157, 0.26464179, 0.41627503, 0.25271161],\n",
       "        [0.07715067, 0.18612696, 0.50647898, 0.23024339],\n",
       "        [0.14478994, 0.07462302, 0.48306238, 0.29752466],\n",
       "        [0.08544132, 0.24851049, 0.53837544, 0.12767275],\n",
       "        [0.15564425, 0.18919874, 0.43869338, 0.21646363],\n",
       "        [0.02553529, 0.1258932 , 0.29235844, 0.55621307],\n",
       "        [0.07604748, 0.19032469, 0.54189543, 0.1917324 ],\n",
       "        [0.11962011, 0.29291411, 0.47129881, 0.11616697],\n",
       "        [0.19275595, 0.13517877, 0.56734832, 0.10471696],\n",
       "        [0.29321816, 0.02707198, 0.54215911, 0.13755074],\n",
       "        [0.12546781, 0.05835499, 0.60962919, 0.20654801]]),\n",
       " -183.910076537514)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array(\n",
    "[[2., 5., 3., 0., 0.],\n",
    " [3., 5., 0., 4., 3.],\n",
    " [2., 0., 3., 3., 1.],\n",
    " [4., 0., 4., 5., 2.],\n",
    " [3., 4., 0., 0., 4.],\n",
    " [1., 0., 4., 5., 5.],\n",
    " [2., 5., 0., 0., 1.],\n",
    " [3., 0., 5., 4., 3.],\n",
    " [0., 5., 3., 3., 3.],\n",
    " [2., 0., 0., 3., 3.],\n",
    " [3., 4., 3., 3., 3.],\n",
    " [1., 5., 3., 0., 1.],\n",
    " [4., 5., 3., 4., 3.],\n",
    " [1., 4., 0., 5., 2.],\n",
    " [1., 5., 3., 3., 5.],\n",
    " [3., 5., 3., 4., 3.],\n",
    " [3., 0., 0., 4., 2.],\n",
    " [3., 5., 3., 5., 1.],\n",
    " [2., 4., 5., 5., 0.],\n",
    " [2., 5., 4., 4., 2.]])\n",
    "K=4\n",
    "Mu=np.array([[2., 4., 5., 5., 0.],\n",
    " [3., 5., 0., 4., 3.],\n",
    " [2., 5., 4., 4., 2.],\n",
    " [0., 5., 3., 3., 3.]])\n",
    "Var= np.array([5.93, 4.87, 3.99, 4.51])\n",
    "P= np.array([0.25, 0.25, 0.25, 0.25])\n",
    "\n",
    "estep(X,Var,Mu,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bb14b3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0.41212084, 0.30996844, 0.27791072],\n",
      "       [0.55740093, 0.2420324 , 0.20056667],\n",
      "       [0.42126855, 0.45299707, 0.12573438],\n",
      "       [0.51289877, 0.3599786 , 0.12712263],\n",
      "       [0.41321342, 0.46332157, 0.12346501],\n",
      "       [0.35565243, 0.28362751, 0.36072007],\n",
      "       [0.53111301, 0.07158895, 0.39729804],\n",
      "       [0.64307581, 0.23688652, 0.12003767],\n",
      "       [0.43850807, 0.43056952, 0.13092241],\n",
      "       [0.60469179, 0.24610356, 0.14920465],\n",
      "       [0.35565243, 0.28362751, 0.36072007],\n",
      "       [0.38880461, 0.49411041, 0.11708498],\n",
      "       [0.49848898, 0.3487486 , 0.15276241],\n",
      "       [0.62875702, 0.09541061, 0.27583237],\n",
      "       [0.46220518, 0.06602074, 0.47177408],\n",
      "       [0.50908165, 0.0810036 , 0.40991475],\n",
      "       [0.44397298, 0.49447706, 0.06154996],\n",
      "       [0.37638419, 0.29289134, 0.33072447],\n",
      "       [0.49432872, 0.34653653, 0.15913474]]), -12.69117868224124)\n"
     ]
    }
   ],
   "source": [
    "X= np.array([[0.17091235, 0.        ,],\n",
    " [0.        , 0.41413555],\n",
    " [0.        , 0.06817081],\n",
    " [0.72061729, 0.        ],\n",
    " [0.        , 0.05301587],\n",
    " [0.        , 0.        ],\n",
    " [0.45509733, 0.92789095],\n",
    " [0.97172091, 0.50066923],\n",
    " [0.        , 0.10131313],\n",
    " [0.52241939, 0.44011616],\n",
    " [0.        , 0.        ],\n",
    " [0.        , 0.00803926],\n",
    " [0.54238683, 0.        ],\n",
    " [0.74422357, 0.87086151],\n",
    " [0.28738306, 0.91490064],\n",
    " [0.        , 0.84690547],\n",
    " [0.97385819, 0.07301752],\n",
    " [0.07987699, 0.        ],\n",
    " [0.5105531 , 0.        ]])\n",
    "K= 3\n",
    "Mu= np.array([[0.52241939, 0.44011616],\n",
    " [0.5105531 , 0.        ],\n",
    " [0.        , 0.84690547]])\n",
    "Var= [0.15674446, 0.17839253, 0.33471588]\n",
    "P= [0.35565243, 0.28362751, 0.36072007]\n",
    "print(estep(X,Var,Mu,P))\n",
    "output = {\n",
    "\"post\":np.array([[0.35870418, 0.2878204,  0.35347542],\n",
    " [0.50275341, 0.2328912 , 0.26435539],\n",
    " [0.38709827, 0.44406836, 0.16883337],\n",
    " [0.47372303, 0.35470048, 0.17157649],\n",
    " [0.37982111, 0.45433838, 0.16584051],\n",
    " [0.35565243, 0.28362751, 0.36072007],\n",
    " [0.53111301, 0.07158896, 0.39729803],\n",
    " [0.64307581, 0.23688652, 0.12003767],\n",
    " [0.40260848, 0.42173616, 0.17565536],\n",
    " [0.60469179, 0.24610356, 0.14920465],\n",
    " [0.35565243, 0.28362751, 0.36072007],\n",
    " [0.35767602, 0.48492509, 0.15739889],\n",
    " [0.45575094, 0.34015489, 0.20409416],\n",
    " [0.62875702, 0.09541061, 0.27583237],\n",
    " [0.46220519, 0.06602074, 0.47177407],\n",
    " [0.42618442, 0.0723447 , 0.50147088],\n",
    " [0.44397297, 0.49447706, 0.06154996],\n",
    " [0.32110912, 0.26657538, 0.4123155 ],\n",
    " [0.45079673, 0.33713681, 0.21206646]]),\n",
    "\"LL\":-11.597554\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fccc5185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0.03777398, 0.16930007, 0.12932721, 0.15691668, 0.16067232,\n",
      "        0.17455926, 0.17145049],\n",
      "       [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101,\n",
      "        0.15374183, 0.1510038 ],\n",
      "       [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101,\n",
      "        0.15374183, 0.1510038 ],\n",
      "       [0.63268424, 0.06462784, 0.04936878, 0.05990065, 0.06133432,\n",
      "        0.06663545, 0.06544872],\n",
      "       [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101,\n",
      "        0.15374183, 0.1510038 ],\n",
      "       [0.96182242, 0.0067172 , 0.00513123, 0.00622588, 0.00637489,\n",
      "        0.00692587, 0.00680252],\n",
      "       [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101,\n",
      "        0.15374183, 0.1510038 ],\n",
      "       [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101,\n",
      "        0.15374183, 0.1510038 ],\n",
      "       [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101,\n",
      "        0.15374183, 0.1510038 ],\n",
      "       [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101,\n",
      "        0.15374183, 0.1510038 ],\n",
      "       [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101,\n",
      "        0.15374183, 0.1510038 ],\n",
      "       [0.94919153, 0.00893956, 0.00682887, 0.00828568, 0.00848399,\n",
      "        0.00921726, 0.00905311],\n",
      "       [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101,\n",
      "        0.15374183, 0.1510038 ],\n",
      "       [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101,\n",
      "        0.15374183, 0.1510038 ],\n",
      "       [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101,\n",
      "        0.15374183, 0.1510038 ],\n",
      "       [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101,\n",
      "        0.15374183, 0.1510038 ],\n",
      "       [0.01031939, 0.17413061, 0.13301722, 0.16139388, 0.16525669,\n",
      "        0.17953985, 0.17634237]]), -2.861004834500859)\n"
     ]
    }
   ],
   "source": [
    "X= np.array([[0.        , 0.1037424 ],\n",
    " [0.        , 0.        ],\n",
    " [0.        , 0.        ],\n",
    " [0.52133281, 0.        ],\n",
    " [0.        , 0.        ],\n",
    " [0.6726321 , 0.        ],\n",
    " [0.        , 0.        ],\n",
    " [0.        , 0.        ],\n",
    " [0.        , 0.        ],\n",
    " [0.        , 0.        ],\n",
    " [0.        , 0.        ],\n",
    " [0.65716263, 0.        ],\n",
    " [0.        , 0.        ],\n",
    " [0.        , 0.        ],\n",
    " [0.        , 0.        ],\n",
    " [0.        , 0.        ],\n",
    " [0.00270617, 0.        ]])\n",
    "K= 7\n",
    "Mu= np.array([[0.65716263, 0.        ],\n",
    " [0.        , 0.        ],\n",
    " [0.        , 0.        ],\n",
    " [0.        , 0.        ],\n",
    " [0.        , 0.        ],\n",
    " [0.        , 0.        ],\n",
    " [0.        , 0.        ]])\n",
    "Var= np.array([0.17858765, 0.03431925, 0.03431925, 0.03431925, 0.03431925, 0.03431925, 0.03431925])\n",
    "P= np.array([0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101, 0.15374183, 0.1510038 ])\n",
    "print(estep(X,Var,Mu,P))\n",
    "Output:{\n",
    "\"post\":np.array([[0.08219108, 0.16148505, 0.12335736, 0.14967328, 0.15325556, 0.16650147, 0.1635362 ],\n",
    " [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101, 0.15374183, 0.1510038 ],\n",
    " [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101, 0.15374183, 0.1510038 ],\n",
    " [0.79712743, 0.03569467, 0.02726692, 0.0330838 , 0.03387562, 0.0368035 , 0.03614806],\n",
    " [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101, 0.15374183, 0.1510038 ],\n",
    " [0.98289731, 0.00300916, 0.00229867, 0.00278905, 0.0028558 , 0.00310263, 0.00304738],\n",
    " [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101, 0.15374183, 0.1510038 ],\n",
    " [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101, 0.15374183, 0.1510038 ],\n",
    " [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101, 0.15374183, 0.1510038 ],\n",
    " [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101, 0.15374183, 0.1510038 ],\n",
    " [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101, 0.15374183, 0.1510038 ],\n",
    " [0.97707275, 0.00403396, 0.00308152, 0.0037389 , 0.00382839, 0.00415928, 0.0040852 ],\n",
    " [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101, 0.15374183, 0.1510038 ],\n",
    " [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101, 0.15374183, 0.1510038 ],\n",
    " [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101, 0.15374183, 0.1510038 ],\n",
    " [0.15252625, 0.14910984, 0.11390402, 0.13820325, 0.14151101, 0.15374183, 0.1510038 ],\n",
    " [0.02323307, 0.17185849, 0.13128157, 0.15928796, 0.16310036, 0.17719716, 0.1740414 ]]),\n",
    "\"LL\":-4.443649}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "47436a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6726321, 0.       ])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "818df538",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= np.array([[0.17091235, 0.        ,],\n",
    " [0.        , 0.41413555],\n",
    " [0.        , 0.06817081],\n",
    " [0.72061729, 0.        ],\n",
    " [0.        , 0.05301587],\n",
    " [0.        , 0.        ],\n",
    " [0.45509733, 0.92789095],\n",
    " [0.97172091, 0.50066923],\n",
    " [0.        , 0.10131313],\n",
    " [0.52241939, 0.44011616],\n",
    " [0.        , 0.        ],\n",
    " [0.        , 0.00803926],\n",
    " [0.54238683, 0.        ],\n",
    " [0.74422357, 0.87086151],\n",
    " [0.28738306, 0.91490064],\n",
    " [0.        , 0.84690547],\n",
    " [0.97385819, 0.07301752],\n",
    " [0.07987699, 0.        ],\n",
    " [0.5105531 , 0.        ]])\n",
    "K= 3\n",
    "Mu= np.array([[0.52241939, 0.44011616],\n",
    " [0.5105531 , 0.        ],\n",
    " [0.        , 0.84690547]])\n",
    "Var= [0.15674446, 0.17839253, 0.33471588]\n",
    "P= [0.35565243, 0.28362751, 0.36072007]\n",
    "# estep(X,Var,Mu,P)\n",
    "def posterior_prob(X,var,Mu,p):\n",
    "    temp = X[X != 0] - Mu[np.where(X != 0)[0]]\n",
    "    print(temp)\n",
    "#     temp = X - Mu\n",
    "    sum_sq = np.dot(temp.T, temp)\n",
    "    dist = np.sqrt(sum_sq)**2\n",
    "    if dist == 0.0 and np.count_nonzero(X) ==0:\n",
    "        return p\n",
    "    else:\n",
    "        return p*(1/((2*math.pi*var)**(2/2)))*math.exp(-(1/(2*var))*dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "39dce964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17091235]\n",
      "[0.52241939]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.1235572])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X[0][X[0] != 0])\n",
    "print(Mu[0][np.where(X[0] != 0)[0]])\n",
    "x_m = X[0][X[0] != 0] - Mu[0][np.where(X[0] != 0)[0]]\n",
    "x_m**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7d2e93cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.35150704]\n"
     ]
    }
   ],
   "source": [
    "print(X[0][X[0] != 0] - Mu[0][np.where(X[0] != 0)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "732c20b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17091235 0.        ]\n",
      "[-0.35150704]\n",
      "[-0.33964075]\n",
      "[0.17091235]\n",
      "0.24349089094433438 0.18313679666060134 0.16419632667179038\n",
      "0.41212084319627834 0.3099684376993264 0.27791071910439513\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "a = posterior_prob(X[0],Var[0],Mu[0],P[0])\n",
    "b = posterior_prob(X[0],Var[1],Mu[1],P[1])\n",
    "c = posterior_prob(X[0],Var[2],Mu[2],P[2])\n",
    "print(a,b,c)\n",
    "s = a + b + c\n",
    "print(a/s,b/s,c/s)\n",
    "# [0.35870418, 0.2878204,  0.35347542]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "179f2e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.identity(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c0d7f121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35565243, 0.28362751, 0.36072007])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.array([np.log(1) + np.log(P[0] + 1e-16), np.log(1) + np.log(P[1] + 1e-16), np.log(1) + np.log(P[2] + 1e-16)])\n",
    "logsumexp(r)\n",
    "np.exp(r - logsumexp(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a0a52e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 0, 1, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([0, 1, 2])\n",
    "K=1\n",
    "print (a)\n",
    "np.tile(a, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "320807fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17091235, 0.        ],\n",
       "       [0.17091235, 0.        ]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.tile(X[0,:],(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "2b997db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 2)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b437619e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17091235])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(X[0,:],(1,1)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "653d7ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "371a962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mstep(X: np.ndarray, post: np.ndarray, mu: np.ndarray,var: np.ndarray,p: np.ndarray, min_variance: float = .25):\n",
    "    \"\"\"M-step: Updates the gaussian mixture by maximizing the log-likelihood\n",
    "    of the weighted dataset\n",
    "\n",
    "    Args:\n",
    "        X: (n, d) array holding the data, with incomplete entries (set to 0)\n",
    "        post: (n, K) array holding the soft counts\n",
    "            for all components for all examples\n",
    "        mixture: the current gaussian mixture\n",
    "        min_variance: the minimum variance for each gaussian\n",
    "\n",
    "    Returns:\n",
    "        GaussianMixture: the new gaussian mixture\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    K = mu.shape[0]\n",
    "    mu = mu\n",
    "    var = var\n",
    "\n",
    "    # Update weights (p)\n",
    "    p = np.sum(post, axis=0) / n\n",
    "\n",
    "    mu = np.array([[0.41970858, 0.57419602], [0.46514641, 0.50509648], [0.45167656, 0.64343368], [0.41703438, 0.87008726], [0.36824154, 0.        ], [0.35384957, 0.44162885]])\n",
    "\n",
    "    for k in range(K):\n",
    "        #0.75\n",
    "#         diff = X - mu[k]\n",
    "#         squared_diff = np.sum(post[:, k, None] * (diff ** 2), axis=0)\n",
    "#         weighted_sum = np.sum(post[:, k])\n",
    "#         var[k] = max(min_variance, np.sum(squared_diff) / (np.count_nonzero(X) * weighted_sum))\n",
    "        \n",
    "        sum_sq_diff=np.zeros((n,d))\n",
    "        for i in range(n):\n",
    "            if np.count_nonzero(X[i]) != 0:\n",
    "                diff = (X[i][X[i] != 0] - mu[k][np.where(X[i] != 0)[0]])\n",
    "            else:\n",
    "                diff = 1\n",
    "            sum_sq_diff[i] = (post[i,k] * (diff**2))\n",
    "        result = np.sum(sum_sq_diff)/(np.sum(post[:,k]) * np.count_nonzero(X))\n",
    "        var[k] = max(min_variance, result)\n",
    "\n",
    "    return mu, var, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "a247e89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.41970858, 0.57419602],\n",
       "        [0.46514641, 0.50509648],\n",
       "        [0.45167656, 0.64343368],\n",
       "        [0.41703438, 0.87008726],\n",
       "        [0.36824154, 0.        ],\n",
       "        [0.35384957, 0.44162885]]),\n",
       " array([0.25, 0.25, 0.25, 0.25, 0.25, 0.25]),\n",
       " array([0.1680912 , 0.15835331, 0.21384187, 0.14223565, 0.14295074,\n",
       "        0.17452722]))"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array([[0.85794562, 0.84725174],\n",
    " [0.6235637 , 0.38438171],\n",
    " [0.29753461, 0.05671298],\n",
    " [0.        , 0.47766512],\n",
    " [0.        , 0.        ],\n",
    " [0.3927848 , 0.        ],\n",
    " [0.        , 0.64817187],\n",
    " [0.36824154, 0.        ],\n",
    " [0.        , 0.87008726],\n",
    " [0.47360805, 0.        ],\n",
    " [0.        , 0.        ],\n",
    " [0.        , 0.        ],\n",
    " [0.53737323, 0.75861562],\n",
    " [0.10590761, 0.        ],\n",
    " [0.18633234, 0.        ]])\n",
    "K= 6\n",
    "mu=np.array([[0.6235637 , 0.38438171],\n",
    "       [0.        , 0.64817187],\n",
    "       [0.        , 0.87008726],\n",
    "       [0.47360805, 0.        ],\n",
    "       [0.18633234, 0.        ],\n",
    "       [0.        , 0.        ]])\n",
    "var=np.array([0.16865269, 0.19909648, 0.3077471 , 0.15453681, 0.13335001,\n",
    "       0.1637321 ])\n",
    "p=np.array([0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
    "       0.16666667])\n",
    "post=np.array([[0.15765074, 0.20544344, 0.17314824, 0.15652173, 0.12169798, 0.18553787],\n",
    " [0.1094766 , 0.22310587, 0.24109142, 0.0959303 , 0.19807563, 0.13232018],\n",
    " [0.22679645, 0.36955206, 0.02836173, 0.03478709, 0.00807236, 0.33243031],\n",
    " [0.16670188, 0.18637975, 0.20964608, 0.17120102, 0.09886116, 0.16721011],\n",
    " [0.04250305, 0.22996176, 0.05151538, 0.33947585, 0.18753121, 0.14901275],\n",
    " [0.09799086, 0.28677458, 0.16895715, 0.21054678, 0.0069597 , 0.22877093],\n",
    " [0.16764519, 0.16897033, 0.25848053, 0.18674186, 0.09846462, 0.11969746],\n",
    " [0.28655211, 0.02473762, 0.27387452, 0.27546459, 0.08641467, 0.05295649],\n",
    " [0.11353057, 0.13090863, 0.20522811, 0.15786368, 0.35574052, 0.03672849],\n",
    " [0.10510461, 0.08116927, 0.3286373 , 0.12745369, 0.23464272, 0.12299241],\n",
    " [0.09757735, 0.06774952, 0.40286261, 0.08481828, 0.1206645 , 0.22632773],\n",
    " [0.24899344, 0.02944918, 0.25413459, 0.02914503, 0.29614373, 0.14213403],\n",
    " [0.35350682, 0.21890411, 0.26755234, 0.01418274, 0.10235276, 0.04350123],\n",
    " [0.15555757, 0.06236572, 0.16703133, 0.21760554, 0.03369562, 0.36374421],\n",
    " [0.1917808 , 0.08982788, 0.17710673, 0.03179658, 0.19494387, 0.31454414]])\n",
    "\n",
    "# Mu: [[0.41970858 0.57419602],\n",
    "#  [0.46514641 0.50509648],\n",
    "#  [0.45167656 0.64343368],\n",
    "#  [0.41703438 0.87008726],\n",
    "#  [0.36824154 0.        ],\n",
    "#  [0.35384957 0.44162885]]\n",
    "# Var: [0.25       0.25       0.25       0.25       0.28690463 0.25      ]\n",
    "# P: [0.1680912  0.15835331 0.21384187 0.14223565 0.14295074 0.17452722]\n",
    "mstep(X,post,mu,var,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "f6b53f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_sq_diff 0.9098538394219342\n",
      "cu_pku 34.3081768\n",
      "result -  0.026520028876088054\n",
      "end result -  0.25\n"
     ]
    }
   ],
   "source": [
    "n,d = X.shape\n",
    "k=4\n",
    "mu = np.array([[0.41970858, 0.57419602], [0.46514641, 0.50509648], [0.45167656, 0.64343368], [0.41703438, 0.87008726], [0.36824154, 0.        ], [0.35384957, 0.44162885]])\n",
    "\n",
    "# sum_sq_diff = np.sum(post[:, k, None] * X - mu[k] ** 2, axis=0).sum()\n",
    "sum_sq_diff=np.zeros((n,2))\n",
    "for i in range(n):\n",
    "#     sum_sq_diff[i] = (post[i,k] * (X[i] - mu[k])**2)\n",
    "    if np.count_nonzero(X[i]) != 0:\n",
    "        diff = (X[i][X[i] != 0] - mu[k][np.where(X[i] != 0)[0]])\n",
    "    else:\n",
    "        diff = 0\n",
    "    sum_sq_diff[i] = (post[i,k] * (diff**2))\n",
    "sum_sq_diff = np.sum(sum_sq_diff)\n",
    "print(\"sum_sq_diff\",sum_sq_diff)\n",
    "cu_pku = np.sum(post[:,k]) * np.count_nonzero(X)\n",
    "print(\"cu_pku\",cu_pku)\n",
    "result = sum_sq_diff/cu_pku\n",
    "print(\"result - \",result)\n",
    "print(\"end result - \",max(0.25, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ddafd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f42b929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
